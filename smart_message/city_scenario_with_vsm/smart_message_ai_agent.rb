#!/usr/bin/env ruby
# smart_message_ai_agent.rb
#
# Abstract base class for building AI agents that can dynamically discover,
# select, and use SmartMessage classes for communication based on context.
#
# This pattern enables AI agents to:
# 1. Discover available message types through introspection
# 2. Use LLM to select appropriate messages for scenarios
# 3. Generate valid message property values using AI
# 4. Handle validation errors with AI-assisted correction
# 5. Publish messages through SmartMessage transport

require 'ruby_llm'
require 'json'
require 'securerandom'

class SmartMessageAIAgent
  attr_reader :service_name, :llm, :ai_available, :logger

  def initialize(service_name, logger = nil)
    @service_name = service_name
    @logger = logger || default_logger
    @message_cache = {}
    @retry_attempts = 3
    
    setup_ai
    logger.info("#{self.class} initialized as '#{@service_name}' - AI-powered messaging agent ready")
  end

  # Override this method to configure RubyLLM with your API keys
  def configure_rubyllm
    RubyLLM.configure do |config|
      config.anthropic_api_key = ENV.fetch('ANTHROPIC_API_KEY', nil)
      config.openai_api_key = ENV.fetch('OPENAI_API_KEY', nil)
      # Add other provider configurations as needed
      
      config.log_file = "log/#{@service_name}_llm.log"
      config.log_level = :info
    end
  end

  # Override this to specify which module contains your message classes
  # Default: Messages
  def message_module
    Messages
  end

  # Override this to filter which message classes are available to the agent
  # Return true to include the message class, false to exclude
  def include_message_class?(message_class)
    true
  end

  # Override this to provide scenario-specific context for message selection
  def build_selection_context(scenario)
    "An AI agent needs to send a message for this scenario: #{scenario[:description]}"
  end

  # Override this to provide scenario-specific context for property generation
  def build_property_context(scenario, message_class)
    "Generate realistic values for a #{message_class} message based on: #{scenario[:description]}"
  end

  # Override this to provide fallback values for specific message types
  def generate_fallback_values(message_class, scenario = nil)
    {
      'timestamp' => Time.now.iso8601,
      'from' => @service_name,
      'details' => "Generated by #{@service_name} agent"
    }
  end

  # Core method to send a message based on a scenario
  def send_message_for_scenario(scenario)
    logger.info("Processing scenario: #{scenario[:type]}")
    
    # Step 1: Discover available messages
    available_messages = discover_message_types
    
    # Step 2: Select appropriate message type
    selected_class = select_message_type(available_messages, scenario)
    return nil unless selected_class
    
    # Step 3: Generate and publish message with retry logic
    publish_with_retry(selected_class, scenario)
  end

  # Discover all available SmartMessage classes
  def discover_message_types
    return @message_cache if @message_cache.any?
    
    logger.info("Discovering message types from #{message_module}")
    
    message_module.constants.each do |const_name|
      const = message_module.const_get(const_name)
      
      if const.is_a?(Class) && const < SmartMessage::Base && include_message_class?(const)
        description = const.respond_to?(:description) ? const.description : "No description available"
        @message_cache[const_name.to_s] = {
          class: const,
          description: description
        }
        logger.debug("Discovered: #{const_name} - #{description[0..100]}")
      end
    end
    
    logger.info("Discovered #{@message_cache.size} message types")
    @message_cache
  end

  # Use AI to select the most appropriate message type
  def select_message_type(available_messages, scenario)
    logger.info("Selecting message type for scenario: #{scenario[:type]}")
    
    if @ai_available
      selected = ai_select_message(available_messages, scenario)
      return selected if selected
    end
    
    # Fallback selection logic
    fallback_select_message(available_messages, scenario)
  end

  # Generate message instance with AI-provided or fallback values
  def generate_message_instance(message_class, scenario, validation_errors = [])
    properties = collect_property_metadata(message_class)
    
    values = if @ai_available
      ai_generate_properties(message_class, properties, scenario, validation_errors)
    else
      generate_fallback_values(message_class, scenario)
    end
    
    # Ensure 'from' is set to our service name
    values['from'] = @service_name
    
    # Create instance
    kwargs = values.transform_keys(&:to_sym)
    message_class.new(**kwargs)
  rescue => e
    logger.error("Failed to create message instance: #{e.message}")
    raise
  end

  # Publish message with retry on validation errors
  def publish_with_retry(message_class, scenario)
    validation_errors = []
    
    @retry_attempts.times do |attempt|
      begin
        message = generate_message_instance(message_class, scenario, validation_errors)
        message.publish
        logger.info("Successfully published #{message_class} (attempt #{attempt + 1})")
        return message
      rescue => e
        if validation_error = parse_validation_error(e.message)
          validation_errors = build_validation_context(validation_error)
          logger.warn("Validation error on attempt #{attempt + 1}: #{validation_error[:message]}")
          next if attempt < @retry_attempts - 1
        end
        raise
      end
    end
  end

  private

  def setup_ai
    begin
      configure_rubyllm
      @llm = RubyLLM.chat
      @ai_available = true
      logger.info("AI model initialized successfully")
    rescue => e
      @ai_available = false
      logger.warn("AI not available: #{e.message}. Using fallback logic.")
    end
  end

  def default_logger
    require 'logger'
    Logger.new("log/#{@service_name}.log")
  end

  def ai_select_message(available_messages, scenario)
    descriptions = available_messages.map { |name, info| "#{name}: #{info[:description]}" }.join("\n\n")
    
    prompt = <<~PROMPT
      #{build_selection_context(scenario)}
      
      Available message types:
      #{descriptions}
      
      Which message type is most appropriate? Respond with ONLY the class name.
    PROMPT
    
    begin
      response = @llm.ask(prompt)
      class_name = response.content.strip
      
      if available_messages[class_name]
        logger.info("AI selected: #{class_name}")
        return available_messages[class_name][:class]
      end
    rescue => e
      logger.error("AI selection failed: #{e.message}")
    end
    
    nil
  end

  def fallback_select_message(available_messages, scenario)
    # Simple keyword matching fallback
    type_keyword = scenario[:type].to_s.downcase
    
    # Try exact match
    match = available_messages.find { |name, _| name.downcase.include?(type_keyword) }
    return match[1][:class] if match
    
    # Try partial match on description
    match = available_messages.find { |_, info| info[:description].downcase.include?(type_keyword) }
    return match[1][:class] if match
    
    # Return first available
    first = available_messages.first
    first[1][:class] if first
  end

  def collect_property_metadata(message_class)
    return {} unless message_class.respond_to?(:property_descriptions)
    
    properties = {}
    message_class.property_descriptions.each do |prop, desc|
      enhanced_desc = desc.to_s
      
      # Add validation constraints if available
      if message_class.respond_to?(:property_validations)
        validation = message_class.property_validations[prop]
        if validation && validation[:validation_message]
          enhanced_desc += " (#{validation[:validation_message]})"
        end
      end
      
      # Check for valid value constants
      const_name = "VALID_#{prop.to_s.upcase}S"
      if message_class.const_defined?(const_name)
        valid_values = message_class.const_get(const_name)
        enhanced_desc += " Valid values: #{valid_values.join(', ')}"
      end
      
      properties[prop] = enhanced_desc
    end
    
    properties
  end

  def ai_generate_properties(message_class, properties, scenario, validation_errors)
    properties_text = properties.map { |prop, desc| "#{prop}: #{desc}" }.join("\n")
    
    error_context = if validation_errors.any?
      "\n\nPREVIOUS VALIDATION ERRORS:\n" + validation_errors.join("\n") +
      "\n\nFix these specific properties with valid values."
    else
      ""
    end
    
    prompt = <<~PROMPT
      #{build_property_context(scenario, message_class)}
      
      Properties to fill:
      #{properties_text}
      
      The 'from' field should be '#{@service_name}'.
      #{error_context}
      
      Respond with a JSON object containing the property values.
    PROMPT
    
    begin
      response = @llm.ask(prompt)
      JSON.parse(response.content)
    rescue => e
      logger.error("AI property generation failed: #{e.message}")
      generate_fallback_values(message_class, scenario)
    end
  end

  def parse_validation_error(error_message)
    # Parse validation errors in various formats
    if error_message =~ /Messages::(\w+)#(\w+):\s*(.+)/
      return {
        class_name: $1,
        property: $2,
        message: $3,
        valid_values: extract_valid_values($3)
      }
    elsif error_message =~ /property\s+'(\w+)'\s+is\s+required/i
      return {
        property: $1,
        message: error_message
      }
    elsif error_message.include?("ValidationError")
      return {
        property: "unknown",
        message: error_message
      }
    end
    
    nil
  end

  def extract_valid_values(message)
    if message =~ /must be(?:\s+one\s+of)?:\s*(.+)/i
      $1.strip.split(/,\s*/).map(&:strip)
    end
  end

  def build_validation_context(validation_error)
    context = ["Property '#{validation_error[:property]}' has invalid value."]
    context << "Error: #{validation_error[:message]}"
    context << "Valid values: #{validation_error[:valid_values].join(', ')}" if validation_error[:valid_values]
    context
  end
end

# Example concrete implementation
class ExampleAIAgent < SmartMessageAIAgent
  def initialize
    super('example_agent')
  end

  # Customize which messages this agent can use
  def include_message_class?(message_class)
    # Only include emergency-related messages
    message_class.to_s.include?('Emergency') || message_class.to_s.include?('Alert')
  end

  # Provide domain-specific context
  def build_selection_context(scenario)
    "An emergency response agent observed: #{scenario[:description]}. Select the appropriate emergency message type."
  end

  def build_property_context(scenario, message_class)
    "Generate emergency report values for #{message_class}. Incident: #{scenario[:description]}. Use high severity for serious incidents."
  end

  # Domain-specific fallback values
  def generate_fallback_values(message_class, scenario = nil)
    base_values = super
    
    # Add emergency-specific defaults
    if message_class.to_s.include?('Emergency')
      base_values.merge!({
        'severity' => 'high',
        'response_required' => true,
        'location' => 'Unknown Location',
        'reported_by' => @service_name
      })
    end
    
    base_values
  end
end